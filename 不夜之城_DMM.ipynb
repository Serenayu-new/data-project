{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serenayu/Documents/data-project/data_project/gsheets.py:81: UserWarning: No columns named '日期' or 'date'.\n",
      "  warnings.warn(\"No columns named '日期' or 'date'.\")\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from data_project.gsheets import DateSheet\n",
    "from datetime import date, timedelta, datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "target_date = (date.today() - timedelta(days=1))\n",
    "\n",
    "async def create_sheet():\n",
    "    return DateSheet('[RP_DMM] Revenue Report', date=target_date.isoformat())\n",
    "\n",
    "task_sheet = asyncio.create_task(create_sheet())\n",
    "await task_sheet\n",
    "mysheet = task_sheet.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Server         UID      Create Time Package ID      Package Name  \\\n",
      "11       1001  1001004732  18/4/2024 18:11       1166         コロネ石お得パック   \n",
      "37       1011  1011006846   2/6/2024 19:13       1166         コロネ石お得パック   \n",
      "56       1007  1007003598  26/4/2024 23:58       1171        星の羅針盤お得パック   \n",
      "57       1007  1007003598  26/4/2024 23:58       1171        星の羅針盤お得パック   \n",
      "59       1005  1005001574   22/4/2024 7:00       1167  SSR獣神の欠片 - セイレーン   \n",
      "...       ...         ...              ...        ...               ...   \n",
      "116272   1002  1002003747  18/4/2024 21:57       1456         コロネ石お得パック   \n",
      "116287   1010  1010000164   8/5/2024 21:13       1456         コロネ石お得パック   \n",
      "116307   1013  1013006958  26/7/2024 19:41       1456         コロネ石お得パック   \n",
      "116332   1013  1013002018    9/7/2024 1:08       1474        星の羅針盤お得パック   \n",
      "116374   1013  1013004604  17/7/2024 10:29       1474        星の羅針盤お得パック   \n",
      "\n",
      "         Package Type price    Purchase Time   分類1   分類2         USD  \\\n",
      "11      TreasureHouse   500   10/6/2024 0:07  不夜之城  活動禮包    3.184044   \n",
      "37      TreasureHouse   500   10/6/2024 0:24  不夜之城  活動禮包    3.184044   \n",
      "56      TreasureHouse  2400   10/6/2024 0:38  不夜之城  活動禮包  15.2834112   \n",
      "57      TreasureHouse  2400   10/6/2024 0:38  不夜之城  活動禮包  15.2834112   \n",
      "59      TreasureHouse  5000   10/6/2024 0:40  不夜之城  活動禮包    31.84044   \n",
      "...               ...   ...              ...   ...   ...         ...   \n",
      "116272  TreasureHouse   500  22/8/2024 21:35  不夜之城  活動禮包    3.419996   \n",
      "116287  TreasureHouse   500  22/8/2024 21:58  不夜之城  活動禮包    3.419996   \n",
      "116307  TreasureHouse   500  22/8/2024 22:14  不夜之城  活動禮包    3.419996   \n",
      "116332  TreasureHouse  2400  22/8/2024 22:37  不夜之城  活動禮包  16.4159808   \n",
      "116374  TreasureHouse  2400  22/8/2024 23:35  不夜之城  活動禮包  16.4159808   \n",
      "\n",
      "                                  Unique ID    Reg Date    PUR Date  \\\n",
      "11             TreasureHouse_1166_コロネ石お得パック  2024-04-18  2024-06-10   \n",
      "37             TreasureHouse_1166_コロネ石お得パック  2024-06-02  2024-06-10   \n",
      "56            TreasureHouse_1171_星の羅針盤お得パック  2024-04-26  2024-06-10   \n",
      "57            TreasureHouse_1171_星の羅針盤お得パック  2024-04-26  2024-06-10   \n",
      "59      TreasureHouse_1167_SSR獣神の欠片 - セイレーン  2024-04-22  2024-06-10   \n",
      "...                                     ...         ...         ...   \n",
      "116272         TreasureHouse_1456_コロネ石お得パック  2024-04-18  2024-08-22   \n",
      "116287         TreasureHouse_1456_コロネ石お得パック  2024-05-08  2024-08-22   \n",
      "116307         TreasureHouse_1456_コロネ石お得パック  2024-07-26  2024-08-22   \n",
      "116332        TreasureHouse_1474_星の羅針盤お得パック  2024-07-09  2024-08-22   \n",
      "116374        TreasureHouse_1474_星の羅針盤お得パック  2024-07-17  2024-08-22   \n",
      "\n",
      "          PUR Week  PUR MTH 購買距離註冊天數     UNI by PUR  USD by Day  \n",
      "11      2024-06-10  2024-06       53   0.3333333333   19.104264  \n",
      "37      2024-06-10  2024-06        8  0.06666666667  94.8845112  \n",
      "56      2024-06-10  2024-06       45  0.09090909091  187.858596  \n",
      "57      2024-06-10  2024-06       45  0.09090909091  187.858596  \n",
      "59      2024-06-10  2024-06       49            0.2  82.1483352  \n",
      "...            ...      ...      ...            ...         ...  \n",
      "116272  2024-08-19  2024-08      126   0.3333333333   5.4719936  \n",
      "116287  2024-08-19  2024-08      106   0.3333333333   5.4719936  \n",
      "116307  2024-08-19  2024-08       27   0.1666666667  67.0319216  \n",
      "116332  2024-08-19  2024-08       44   0.1428571429   54.719936  \n",
      "116374  2024-08-19  2024-08       36              1  16.4159808  \n",
      "\n",
      "[5817 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# Change your sheet\n",
    "mysheet.change_sheet(\"data\", headers_row=2)\n",
    "sheet = mysheet.worksheet\n",
    "\n",
    "data = sheet.get_all_values()\n",
    "\n",
    "# Assuming headers are in the second row (index 1)\n",
    "headers = data[1]\n",
    "data = data[2:]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Filter rows where \"Fan Leoi 1\" column has the value \"Bou Shek\"\n",
    "filtered_df = df[df['分類1'] == '不夜之城']\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the target sheet\n",
    "mysheet = DateSheet('nightless_city_test', date=target_date.isoformat())\n",
    "mysheet.change_sheet('工作表1')\n",
    "sheet = mysheet.worksheet\n",
    "data = filtered_df.copy()\n",
    "data = data.iloc[: 10]  # only update the first 10 rows\n",
    "\n",
    "# define the relation of columns\n",
    "column_names = {\n",
    "    \"userId\": \"userId\",\n",
    "    \"serverPrefix\": \"serverPrefix\",\n",
    "    \"Create Time\": \"CT\",\n",
    "}\n",
    "\n",
    "# rename the col of data\n",
    "data.columns = [column_names.get(c, c).lower() for c in data.columns]\n",
    "\n",
    "# sort & filter columns\n",
    "for header in mysheet.headers:\n",
    "    if header not in data.columns:\n",
    "        data.loc[:, header] = None\n",
    "data = data[mysheet.headers]\n",
    "\n",
    "# sort rows\n",
    "# data['ct'] = data['ct'].str.replace(\" \", \"T\").apply(datetime.fromisoformat)  # convert str into datetime\n",
    "data.sort_values(\"ct\", ascending=True, inplace=True)\n",
    "\n",
    "# compute the cell to paste\n",
    "cell = f\"A{len(sheet.col_values(1)) + 1}\"\n",
    "\n",
    "# update the target sheet\n",
    "sheet.update(cell, data.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mfiltered_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mright\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DataFrame | Series'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'MergeHow'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'IndexLabel | AnyArrayLike | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mleft_on\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'IndexLabel | AnyArrayLike | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mright_on\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'IndexLabel | AnyArrayLike | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mleft_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mright_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msuffixes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Suffixes'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'MergeValidate | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Merge DataFrame or named Series objects with a database-style join.\n",
      "\n",
      "A named Series object is treated as a DataFrame with a single named column.\n",
      "\n",
      "The join is done on columns or indexes. If joining columns on\n",
      "columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      "on indexes or indexes on a column or columns, the index will be passed on.\n",
      "When performing a cross merge, no column specifications to merge on are\n",
      "allowed.\n",
      "\n",
      ".. warning::\n",
      "\n",
      "    If both key columns contain rows where the key is a null value, those\n",
      "    rows will be matched against each other. This is different from usual SQL\n",
      "    join behaviour and can lead to unexpected results.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "right : DataFrame or named Series\n",
      "    Object to merge with.\n",
      "how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      "    Type of merge to be performed.\n",
      "\n",
      "    * left: use only keys from left frame, similar to a SQL left outer join;\n",
      "      preserve key order.\n",
      "    * right: use only keys from right frame, similar to a SQL right outer join;\n",
      "      preserve key order.\n",
      "    * outer: use union of keys from both frames, similar to a SQL full outer\n",
      "      join; sort keys lexicographically.\n",
      "    * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      "      join; preserve the order of the left keys.\n",
      "    * cross: creates the cartesian product from both frames, preserves the order\n",
      "      of the left keys.\n",
      "on : label or list\n",
      "    Column or index level names to join on. These must be found in both\n",
      "    DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      "    to the intersection of the columns in both DataFrames.\n",
      "left_on : label or list, or array-like\n",
      "    Column or index level names to join on in the left DataFrame. Can also\n",
      "    be an array or list of arrays of the length of the left DataFrame.\n",
      "    These arrays are treated as if they are columns.\n",
      "right_on : label or list, or array-like\n",
      "    Column or index level names to join on in the right DataFrame. Can also\n",
      "    be an array or list of arrays of the length of the right DataFrame.\n",
      "    These arrays are treated as if they are columns.\n",
      "left_index : bool, default False\n",
      "    Use the index from the left DataFrame as the join key(s). If it is a\n",
      "    MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "    or a number of columns) must match the number of levels.\n",
      "right_index : bool, default False\n",
      "    Use the index from the right DataFrame as the join key. Same caveats as\n",
      "    left_index.\n",
      "sort : bool, default False\n",
      "    Sort the join keys lexicographically in the result DataFrame. If False,\n",
      "    the order of the join keys depends on the join type (how keyword).\n",
      "suffixes : list-like, default is (\"_x\", \"_y\")\n",
      "    A length-2 sequence where each element is optionally a string\n",
      "    indicating the suffix to add to overlapping column names in\n",
      "    `left` and `right` respectively. Pass a value of `None` instead\n",
      "    of a string to indicate that the column name from `left` or\n",
      "    `right` should be left as-is, with no suffix. At least one of the\n",
      "    values must not be None.\n",
      "copy : bool, default True\n",
      "    If False, avoid copy if possible.\n",
      "\n",
      "    .. note::\n",
      "        The `copy` keyword will change behavior in pandas 3.0.\n",
      "        `Copy-on-Write\n",
      "        <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      "        will be enabled by default, which means that all methods with a\n",
      "        `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      "        ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      "        future version of pandas.\n",
      "\n",
      "        You can already get the future behavior and improvements through\n",
      "        enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      "indicator : bool or str, default False\n",
      "    If True, adds a column to the output DataFrame called \"_merge\" with\n",
      "    information on the source of each row. The column can be given a different\n",
      "    name by providing a string argument. The column will have a Categorical\n",
      "    type with the value of \"left_only\" for observations whose merge key only\n",
      "    appears in the left DataFrame, \"right_only\" for observations\n",
      "    whose merge key only appears in the right DataFrame, and \"both\"\n",
      "    if the observation's merge key is found in both DataFrames.\n",
      "\n",
      "validate : str, optional\n",
      "    If specified, checks if merge is of specified type.\n",
      "\n",
      "    * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      "      left and right datasets.\n",
      "    * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      "      dataset.\n",
      "    * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      "      dataset.\n",
      "    * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame\n",
      "    A DataFrame of the two merged objects.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "merge_ordered : Merge with optional filling/interpolation.\n",
      "merge_asof : Merge on nearest keys.\n",
      "DataFrame.join : Similar method using indices.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "...                     'value': [1, 2, 3, 5]})\n",
      ">>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "...                     'value': [5, 6, 7, 8]})\n",
      ">>> df1\n",
      "    lkey value\n",
      "0   foo      1\n",
      "1   bar      2\n",
      "2   baz      3\n",
      "3   foo      5\n",
      ">>> df2\n",
      "    rkey value\n",
      "0   foo      5\n",
      "1   bar      6\n",
      "2   baz      7\n",
      "3   foo      8\n",
      "\n",
      "Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      "the default suffixes, _x and _y, appended.\n",
      "\n",
      ">>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      "  lkey  value_x rkey  value_y\n",
      "0  foo        1  foo        5\n",
      "1  foo        1  foo        8\n",
      "2  bar        2  bar        6\n",
      "3  baz        3  baz        7\n",
      "4  foo        5  foo        5\n",
      "5  foo        5  foo        8\n",
      "\n",
      "Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      "appended to any overlapping columns.\n",
      "\n",
      ">>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      "...           suffixes=('_left', '_right'))\n",
      "  lkey  value_left rkey  value_right\n",
      "0  foo           1  foo            5\n",
      "1  foo           1  foo            8\n",
      "2  bar           2  bar            6\n",
      "3  baz           3  baz            7\n",
      "4  foo           5  foo            5\n",
      "5  foo           5  foo            8\n",
      "\n",
      "Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      "any overlapping columns.\n",
      "\n",
      ">>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      "Traceback (most recent call last):\n",
      "...\n",
      "ValueError: columns overlap but no suffix specified:\n",
      "    Index(['value'], dtype='object')\n",
      "\n",
      ">>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      ">>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      ">>> df1\n",
      "      a  b\n",
      "0   foo  1\n",
      "1   bar  2\n",
      ">>> df2\n",
      "      a  c\n",
      "0   foo  3\n",
      "1   baz  4\n",
      "\n",
      ">>> df1.merge(df2, how='inner', on='a')\n",
      "      a  b  c\n",
      "0   foo  1  3\n",
      "\n",
      ">>> df1.merge(df2, how='left', on='a')\n",
      "      a  b  c\n",
      "0   foo  1  3.0\n",
      "1   bar  2  NaN\n",
      "\n",
      ">>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      ">>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      ">>> df1\n",
      "    left\n",
      "0   foo\n",
      "1   bar\n",
      ">>> df2\n",
      "    right\n",
      "0   7\n",
      "1   8\n",
      "\n",
      ">>> df1.merge(df2, how='cross')\n",
      "   left  right\n",
      "0   foo      7\n",
      "1   foo      8\n",
      "2   bar      7\n",
      "3   bar      8\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "filtered_df.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  uid country\n",
      "0   a      cn\n",
      "1   b      eu\n",
      "\n",
      "  uid  price\n",
      "0   a   0.99\n",
      "1   a   8.00\n",
      "2   a  12.00\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame([\n",
    "    ['a', 'cn'],\n",
    "    ['b', 'eu'],\n",
    "], columns=['uid', 'country'])\n",
    "\n",
    "df2 = pd.DataFrame([\n",
    "    ['a', 0.99],\n",
    "    ['a', 8],\n",
    "    ['a', 12],\n",
    "    #['b', 4]\n",
    "], columns=['uid', 'price'])\n",
    "\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>cn</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>cn</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>cn</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>eu</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uid country  price\n",
       "0   a      cn   0.99\n",
       "1   a      cn   8.00\n",
       "2   a      cn  12.00\n",
       "3   b      eu   0.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.merge(df2, how='left', on='uid').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>cn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>eu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uid country  price\n",
       "0   a      cn    NaN\n",
       "1   b      eu    NaN\n",
       "0   a     NaN   0.99\n",
       "1   a     NaN   8.00\n",
       "2   a     NaN  12.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.concat([df1, df2])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
